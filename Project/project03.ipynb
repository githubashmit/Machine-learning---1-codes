{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15400df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_file_path = \"wine_quality_data2.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "wine_quality_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(wine_quality_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234ea0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4             0.700         0.00             1.9      0.076   \n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1594            6.2             0.600         0.08             2.0      0.090   \n",
      "1595            5.9             0.550         0.10             2.2      0.062   \n",
      "1596            6.3             0.510         0.13             2.3      0.076   \n",
      "1597            5.9             0.645         0.12             2.0      0.075   \n",
      "1598            6.0             0.310         0.47             3.6      0.067   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        5  \n",
      "1         9.8        5  \n",
      "2         9.8        5  \n",
      "3         9.8        6  \n",
      "4         9.4        5  \n",
      "...       ...      ...  \n",
      "1594     10.5        5  \n",
      "1595     11.2        6  \n",
      "1596     11.0        6  \n",
      "1597     10.2        5  \n",
      "1598     11.0        6  \n",
      "\n",
      "[1599 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(wine_quality_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412b47b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1279, 11)\n",
      "X_test_scaled shape: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset from the local file\n",
    "csv_file_path = \"wine_quality_data2.csv\"\n",
    "wine_quality_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split features and target variable\n",
    "X = wine_quality_data.drop(\"quality\", axis=1)\n",
    "y = wine_quality_data[\"quality\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shape of the preprocessed data\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405b792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.575\n",
      "Random Forest Accuracy: 0.659375\n",
      "Support Vector Machine Accuracy: 0.559375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from the local file\n",
    "csv_file_path = \"wine_quality_data2.csv\"\n",
    "wine_quality_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split features and target variable\n",
    "X = wine_quality_data.drop(\"quality\", axis=1)\n",
    "y = wine_quality_data[\"quality\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "logreg_pred = logreg_model.predict(X_test_scaled)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "# Display accuracy of each model\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e559c661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Hyperparameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Random Forest Accuracy: 0.659375\n",
      "\n",
      "Support Vector Machine Best Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Support Vector Machine Accuracy: 0.609375\n",
      "\n",
      "Logistic Regression Best Hyperparameters: {'C': 0.1}\n",
      "Logistic Regression Accuracy: 0.565625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from the local file\n",
    "csv_file_path = \"wine_quality_data2.csv\"\n",
    "wine_quality_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split features and target variable\n",
    "X = wine_quality_data.drop(\"quality\", axis=1)\n",
    "y = wine_quality_data[\"quality\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {'n_estimators': [50, 100, 150, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\n",
    "rf_grid_search.fit(X_train_scaled, y_train)\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for Support Vector Machine (SVM)\n",
    "svm_param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "svm_grid_search = GridSearchCV(SVC(), svm_param_grid, cv=5)\n",
    "svm_grid_search.fit(X_train_scaled, y_train)\n",
    "svm_best_model = svm_grid_search.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "logreg_grid_search = GridSearchCV(LogisticRegression(max_iter=1000), logreg_param_grid, cv=5)\n",
    "logreg_grid_search.fit(X_train_scaled, y_train)\n",
    "logreg_best_model = logreg_grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best models\n",
    "rf_pred = rf_best_model.predict(X_test_scaled)\n",
    "svm_pred = svm_best_model.predict(X_test_scaled)\n",
    "logreg_pred = logreg_best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy of each model\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "# Display the best hyperparameters and accuracy for each model\n",
    "print(\"Random Forest Best Hyperparameters:\", rf_grid_search.best_params_)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"\\nSupport Vector Machine Best Hyperparameters:\", svm_grid_search.best_params_)\n",
    "print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n",
    "print(\"\\nLogistic Regression Best Hyperparameters:\", logreg_grid_search.best_params_)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204c4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.659375\n",
      "Support Vector Machine Accuracy: 0.609375\n",
      "Logistic Regression Accuracy: 0.565625\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy of each model\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "# Display the accuracy for each model\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e3bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355411be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d8a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
